// Package openAI defines the data structures used for OpenAI API requests and responses.
// It includes models for request payloads, response data, and associated metadata.
package openAI

// ClientRequest represents the request payload sent to the OpenAI API.
type ClientRequest struct {
	// Messages is a list of messages forming the conversation history.
	Messages []*Message `json:"messages"`
}

// Message represents a single message in the conversation.
type Message struct {
	// Role indicates the role of the message sender (e.g., "system", "user", "assistant").
	Role string `json:"role"`
	// Content contains the actual text of the message.
	Content string `json:"content"`
}

// Response represents the response payload received from the OpenAI API.
type Response struct {
	// Id is the unique identifier for the response.
	Id string `json:"id"`
	// Object specifies the type of object returned (e.g., "response").
	Object string `json:"object"`
	// Created is the timestamp of when the response was generated.
	Created int `json:"created"`
	// Model indicates the model used to generate the response.
	Model string `json:"model"`
	// SystemFingerprint is a fingerprint of the system generating the response.
	SystemFingerprint string `json:"system_fingerprint"`
	// Choices contains the list of choices generated by the model.
	Choices []ResponseChoice `json:"choices"`
	// Usage provides information about token usage for the request and response.
	Usage Usage `json:"usage"`
	Error Error `json:"error"`
}

type Error struct {
	Message string `json:"message"`
	Type    string `json:"type"`
}

// ResponseChoice represents a single choice in the response.
type ResponseChoice struct {
	// Index is the position of the choice in the response list.
	Index int `json:"index"`
	// Message contains the generated message for this choice.
	Message Message `json:"message"`
	// Logprobs provides log probability data for the tokens (if available).
	Logprobs interface{} `json:"logprobs"`
	// FinishReason indicates why the generation stopped (e.g., "length", "stop").
	FinishReason string `json:"finish_reason"`
}

// Usage provides information about the token counts for the request and response.
type Usage struct {
	// PromptTokens is the number of tokens used in the input prompt.
	PromptTokens int `json:"prompt_tokens"`
	// CompletionTokens is the number of tokens generated in the response.
	CompletionTokens int `json:"completion_tokens"`
	// TotalTokens is the total number of tokens used (prompt + completion).
	TotalTokens int `json:"total_tokens"`
	// CompletionTokensDetails provides a breakdown of completion tokens.
	CompletionTokensDetails CompletionTokensDetails `json:"completion_tokens_details"`
}

// CompletionTokensDetails provides detailed information about completion tokens.
type CompletionTokensDetails struct {
	// ReasoningTokens is the number of tokens used for reasoning in the response.
	ReasoningTokens int `json:"reasoning_tokens"`
}
